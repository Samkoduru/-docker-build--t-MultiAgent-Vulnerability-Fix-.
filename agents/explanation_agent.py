import os
from langchain.llms import OpenAI
from langchain import PromptTemplate, LLMChain

from agents.guardrails import sanitize_prompt, validate_output

def generate_explanation(vulnerabilities, updated_requirements):
    llm = OpenAI(
        openai_api_key=os.environ.get("OPENAI_API_KEY", ""),
        temperature=0.1
    )
    template = """
    You are an AI that explains security fixes in plain language. 
    Do NOT reveal any secret tokens.

    Vulnerabilities: {vulnerabilities}
    Updated Requirements: {updated_requirements}

    Summarize how these updates address the vulnerabilities and potential impacts.
    """
    final_prompt = template.format(
        vulnerabilities=vulnerabilities,
        updated_requirements=updated_requirements
    )
    sanitized = sanitize_prompt(final_prompt)

    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(sanitized))
    raw_output = chain.run()
    safe_output = validate_output(raw_output)
    return safe_output
