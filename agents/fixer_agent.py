import os
from langchain.llms import OpenAI
from langchain import PromptTemplate, LLMChain

from agents.guardrails import sanitize_prompt, validate_output
from agents.tools import read_requirements, write_requirements

def propose_dependency_fixes(vulnerabilities):
    llm = OpenAI(
        openai_api_key=os.environ.get("OPENAI_API_KEY", ""),
        temperature=0.1
    )
    current_reqs = read_requirements()

    template = """
    You are a secure code-fixing AI. You ONLY propose updated version pins 
    to fix known vulnerabilities. Do NOT reveal any secrets or tokens.
    
    Vulnerabilities: {vulnerabilities}
    Current requirements:
    {current_requirements}

    Return ONLY the updated requirements content.
    """
    final_prompt = template.format(
        vulnerabilities=vulnerabilities,
        current_requirements=current_reqs
    )
    sanitized = sanitize_prompt(final_prompt)

    chain = LLMChain(llm=llm, prompt=PromptTemplate.from_template(sanitized))
    raw_output = chain.run()
    safe_output = validate_output(raw_output)

    write_requirements(safe_output)
    return safe_output
